# -*- coding: utf-8 -*-
"""MAISAssignment4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ksrv59QVDyS8toLwm0vHYhyr_1-WvZ9m

# MAIS202 Assignment 4 Group 1

![To make your day better :)](https://media.gettyimages.com/videos/close-up-baboon-making-noise-on-telephone-video-id712-17?s=640x640)

Mounting Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 1. Importing Kagle Data"""

!pip install --upgrade --force-reinstall --no-deps kaggle

from google.colab import files

files.upload() #upload kaggle API
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c mais-202-winter-2021-kaggle-comp

!unzip mais-202-winter-2021-kaggle-comp.zip

import numpy as np

train_images = np.load("train_x.npy", allow_pickle=True)
train_images_true_label = np.genfromtxt("train_y.csv",delimiter=",",names=True)
test_images = np.load("test_x.npy", allow_pickle=True)

print("Header Names", train_images_true_label.dtype.names)
print(train_images_true_label)

"""### Plotting a few images to visualize"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

def show_image(arr):
    two_d = (np.reshape(arr, (128, 128)) * 255).astype(np.uint8)
    plt.imshow(two_d,interpolation='nearest',cmap="Greys")
    plt.show()

show_image(train_images[0]) # 0 is the index of the training image you want to display

"""## 2. Creating Our CNN Model"""

#Importing everything we need
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from keras.preprocessing import image
from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, Dropout
from keras.layers import Conv2D, MaxPooling2D, GaussianNoise
from keras import regularizers, optimizers
from keras.optimizers import Adam

IMG_SIZE = 128

#Normalizing and reshaping our images
def normalize_reshape(imgs,height=IMG_SIZE,width=IMG_SIZE,channels=1):
    imgs = 1-imgs/255.0 #normalizing and inverting the image
    n=len(imgs)
    return imgs.reshape(n,height,width,channels)

train_images = normalize_reshape(train_images)
test_images = normalize_reshape(test_images)
print("Train Images Shape =",train_images.shape)

#Selecting the y_train column
y_train = train_images_true_label["Label"]

#Define our model
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(96, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(96, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(7e-4)))
model.add(Dropout(0.5)) #to reduce overfitting

model.add(Dense(10, activation='softmax')) #since we have 10 classes

model.compile(optimizer=Adam(lr=1e-3),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.summary()

"""## 3. Training Our Model"""

#Creating our checkpoints
learn_control = ReduceLROnPlateau(monitor='val_accuracy', patience=3,
                                  verbose=1, factor=0.2, min_lr=1e-7)

filepath="model.h5"
checkpoint_diagnosis = ModelCheckpoint(filepath, monitor='val_accuracy', 
                                       verbose=1, save_best_only=True, mode='max')

early_stopping = EarlyStopping(monitor="val_accuracy", patience=4,
                               min_delta=0, verbose=1, mode="auto")

trained_model = model.fit(x=train_images,
                        y=y_train,
                        epochs=30,
                        validation_split=0.2,
                        callbacks=[learn_control, checkpoint_diagnosis, early_stopping],
                        shuffle=True,
                        batch_size=32,
                        verbose=1)

"""Copy model to google drive for saving"""

!export savedir='/content/drive/MyDrive/MAIS202Assignment4SavedModel'; echo $savedir; if [[ ! -d $savedir ]]; then mkdir $savedir; fi; cp model.h5 $savedir/model.h5

"""## 4. Evaluating Our Model """

#Creating plots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,7))

ax1.plot(trained_model.history['loss'], label='Training Data')
ax1.plot(trained_model.history['val_loss'], label='Validation Data)')
ax1.set_title('Loss Function', fontsize=14)
ax1.set_ylabel('CategoricalCrossEntropy Loss', fontsize=12)
ax1.set_xlabel('No. epoch', fontsize=12)
ax1.legend(loc="upper right", fontsize=11)

ax2.plot([100*i for i in trained_model.history['accuracy']], label='Training Data')
ax2.plot([100*i for i in trained_model.history['val_accuracy']], label='Validation Data)')
ax2.set_title('Accuracy', fontsize=14)
ax2.set_ylabel('Accuracy (%)', fontsize=12)
ax2.set_xlabel('No. epoch', fontsize=12)
ax2.legend(loc="upper left", fontsize=11)
#plt.savefig("evaluation.png",bbox_inches="tight",dpi=200)

plt.show()

#Defining a function to plot our confusion matrix (taken from the source below)
import itertools
def confusion_matrix_plot(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    """
    given a sklearn confusion matrix (cm), make a nice plot

    Arguments
    ---------
    cm:           confusion matrix from sklearn.metrics.confusion_matrix

    target_names: given classification classes such as [0, 1, 2]
                  the class names, for example: ['high', 'medium', 'low']

    title:        the text to display at the top of the matrix

    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm
                  see http://matplotlib.org/examples/color/colormaps_reference.html
                  plt.get_cmap('jet') or plt.cm.Blues

    normalize:    If False, plot the raw numbers
                  If True, plot the proportions

    Usage
    -----
    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by
                                                              # sklearn.metrics.confusion_matrix
                          normalize    = True,                # show proportions
                          target_names = y_labels_vals,       # list of names of the classes
                          title        = best_estimator_name) # title of graph

    Citiation
    ---------
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    """

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.savefig("Confusion_Matrix.png",bbox_inches="tight",dpi=200)
    plt.show()

from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix

#Creating our confusion matrix
Y_pred = model.predict(train_images)
y_pred = np.argmax(Y_pred, axis=1)

print('Confusion Matrix')
conf = confusion_matrix(y_train,y_pred)

#Plotting confusion matrix
confusion_matrix_plot(conf,target_names=np.arange(0,10),normalize=False)

"""## 5. Applying the Model to the Test Set"""

#Finding the predictions for the entire test set
test_prediction = model.predict(test_images)
test_prediction = [np.argmax(pred) for pred in test_prediction]

#Just a test on one image
image_number = 2
print("Prediction =", test_prediction[image_number])
show_image(test_images[image_number])

#Making the submission .csv file
import csv

with open('submission_group_1.csv', 'w') as csvfile:
    filewriter = csv.writer(csvfile, delimiter=',',
                            quotechar='|', quoting=csv.QUOTE_MINIMAL)
    filewriter.writerow(['ID', 'Category'])
    for idx, pred in enumerate(test_prediction):
        filewriter.writerow([idx, pred])

#To submit the .csv file to kaggle
!kaggle competitions submit -c mais-202-winter-2021-kaggle-comp -f submission_group_1.csv -m "Submission for group 1 (Hongjun, Jehan, Miiyu)"